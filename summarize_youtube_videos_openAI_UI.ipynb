{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83TkFCvBK-1Z",
        "outputId": "828a15b6-f9c4-4125-8757-ab38ac07aab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embeddings and asking questions to Youtube Videos "
      ],
      "metadata": {
        "id": "AxsAk9iZUObW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ejri/youtube_openai_analysis\n",
        "%cd youtube_openai_analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm5gs5iVUWT5",
        "outputId": "13a50f8f-193f-429a-c20a-6fdd5aef2a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'youtube-gpt'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 109 (delta 56), reused 69 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (109/109), 2.07 MiB | 18.89 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "/content/youtube-gpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "DoAWb1FIUYsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install pyngrok-5.2.1 and youtube_transcript_api-0.5.0\n",
        "!pip install pyngrok==5.2.1 youtube_transcript_api"
      ],
      "metadata": {
        "id": "pHxAZbl5UdjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/weblm/WebLM_interactive_src/openaiapikey.txt /content/youtube_openai_analysis"
      ],
      "metadata": {
        "id": "SXvxyc5hg5Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# quick check if everything is working as expected\n",
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "st.title('Hello World')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6YA_f7qfHwN",
        "outputId": "8ed5ce59-c963-4c7e-ee84-22978f196567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "import whisper\n",
        "from pytube import YouTube\n",
        "from streamlit_chat import message\n",
        "import openai\n",
        "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
        "import os\n",
        "import sys\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def get_video_id_from_video_id_or_url(video_id_or_url):\n",
        "  # if the video id is longer than 11 characters, then it's a url\n",
        "  if len(video_id_or_url) > 11:\n",
        "      # if it's a url, cut it into a video id\n",
        "      return video_id_or_url[-11:]\n",
        "  else:\n",
        "      # it's a video id\n",
        "      return video_id_or_url\n",
        "\n",
        "def get_chunks_from_youtube(video_id):\n",
        "    # fetch the transcript of the video, and chunk it into 10min intervals\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "\n",
        "    chunks = []\n",
        "\n",
        "    start_timestamp = 0.0\n",
        "    current_timestamp_mins = 0.0\n",
        "\n",
        "    current_chunk = []\n",
        "\n",
        "    for entry in transcript:\n",
        "        current_timestamp_mins = entry['start'] / 60.0\n",
        "\n",
        "        # specify the 10 min chunks. this can be changed into less minutes if max_token error pops up. \n",
        "        if current_timestamp_mins - start_timestamp > 10:\n",
        "            # append the chunks into an array\n",
        "            chunks.append(current_chunk)\n",
        "            # reset the start timestamp\n",
        "            start_timestamp = current_timestamp_mins\n",
        "            # reset the current chunk\n",
        "            current_chunk = []\n",
        "\n",
        "        # add the line to the current chunk\n",
        "        current_chunk.append(entry['text'])\n",
        "\n",
        "    # add the last chunk\n",
        "    if len(current_chunk) > 0:\n",
        "        chunks.append(current_chunk)\n",
        "\n",
        "    print(f\"Found {len(chunks)} chunks\")\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def summarize_chunk(index, chunk):\n",
        "    chunk_str = \"\\n\".join(chunk)\n",
        "    prompt = f\"\"\"The following is a section of the transcript of a youtube video. It is section #{index+1}:\n",
        "    {chunk_str}\n",
        "    Summarize this section of the transcript.\"\"\"\n",
        "\n",
        "    if diagnostics:\n",
        "        # print each line of the prompt with a leading # so we can see it in the output\n",
        "        for line in prompt.split('\\n'):\n",
        "            print(f\"# {line}\")\n",
        "    openai.api_key = user_secret\n",
        "    completion = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\", \n",
        "        max_tokens=500, \n",
        "        temperature=0.2,\n",
        "        prompt=prompt,\n",
        "        frequency_penalty=0\n",
        "    )\n",
        "\n",
        "    msg = completion.choices[0].text\n",
        "\n",
        "    if diagnostics:\n",
        "        print(f\"# Response: {msg}\")\n",
        "\n",
        "    return msg\n",
        "\n",
        "def summarize_the_summaries(summaries):\n",
        "\n",
        "    summaries_str = \"\"\n",
        "    for index, summary in enumerate(summaries):\n",
        "        summaries_str += f\"Summary of chunk {index+1}:\\n{summary}\\n\\n\"\n",
        "\n",
        "    prompt = f\"\"\"The following are summaries of a youtube video in 10 minute chunks:\"\n",
        "    {summaries_str}\n",
        "    Summarize the summaries.\"\"\"\n",
        "\n",
        "    if diagnostics:\n",
        "        # print each line of the prompt with a leading # so we can see it in the output\n",
        "        for line in prompt.split('\\n'):\n",
        "            print(f\"# {line}\")\n",
        "    \n",
        "    openai.api_key = user_secret\n",
        "    completion = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\", \n",
        "        max_tokens=500, \n",
        "        temperature=0.2,\n",
        "        prompt=prompt,\n",
        "        frequency_penalty=0\n",
        "    )\n",
        "\n",
        "    overall_msg = completion.choices[0].text\n",
        "\n",
        "    if diagnostics:\n",
        "        print(f\"# Response: {overall_msg}\")\n",
        "\n",
        "    return overall_msg\n",
        "\n",
        "def summarization_video(youtube_link):\n",
        "  \n",
        "  #video_id_or_url = sys.argv[1]\n",
        "  video_id_or_url =  youtube_link\n",
        "\n",
        "  # if the video id or url is a url, extract the video id\n",
        "  video_id = get_video_id_from_video_id_or_url(video_id_or_url)\n",
        "\n",
        "  if len(sys.argv) > 2:\n",
        "      for arg in sys.argv[2:]:\n",
        "          if arg == \"--diagnostics\":\n",
        "              global diagnostics\n",
        "              diagnostics = True\n",
        "\n",
        "          if arg == \"--mentions\":\n",
        "              global include_mentions\n",
        "              include_mentions = True\n",
        "\n",
        "  # chunks = get_chunks(transcript_file_name)\n",
        "  chunks = get_chunks_from_youtube(video_id)\n",
        "\n",
        "  if len(chunks) == 0:\n",
        "      print(\"No chunks found\")\n",
        "      summaries = []\n",
        "      summary_of_summaries= []\n",
        "      return summaries, summary_of_summaries\n",
        "  elif len(chunks) == 1:\n",
        "      summary = summarize_chunk(0, chunks[0])\n",
        "      print(f\"\\nSummary: {summary}\")\n",
        "      summaries = summary\n",
        "      summary_of_summaries= []\n",
        "      return summaries, summary_of_summaries\n",
        "\n",
        "  else:\n",
        "      # summarize each chunk\n",
        "      summaries = []\n",
        "      for index, chunk in enumerate(chunks):\n",
        "          summary = summarize_chunk(index, chunk)\n",
        "          summaries.append(summary)\n",
        "          print(f\"\\nSummary of chunk {index+1}: {summary}\")\n",
        "\n",
        "      # summarize the chunk summaries \n",
        "      summary_of_summaries = summarize_the_summaries(summaries)\n",
        "\n",
        "      print(f\"\\nSummary of summaries: {summary_of_summaries}\")\n",
        "      return summaries, summary_of_summaries\n",
        "\n",
        "# whisper\n",
        "model = whisper.load_model('base')\n",
        "output = ''\n",
        "data = []\n",
        "data_transcription = []\n",
        "data_summarization = []\n",
        "embeddings = []\n",
        "mp4_video = ''\n",
        "audio_file = ''\n",
        "diagnostics = 0\n",
        "include_mentions = 0\n",
        "summaries = []\n",
        "summary_of_summaries= []\n",
        "\n",
        "# Sidebar\n",
        "with st.sidebar:\n",
        "    user_secret = st.text_input(label = \":blue[OpenAI API key]\",\n",
        "                                placeholder = \"Paste your openAI API key, sk-\",\n",
        "                                type = \"password\")\n",
        "    youtube_link = st.text_input(label = \":red[Youtube link]\",\n",
        "                                placeholder = \"\")\n",
        "    if youtube_link and user_secret:\n",
        "        youtube_video = YouTube(youtube_link)\n",
        "        streams = youtube_video.streams.filter(only_audio=True)\n",
        "        stream = streams.first()\n",
        "        if st.button(\"Start Analysis\"):\n",
        "            if os.path.exists(\"word_embeddings.csv\"):\n",
        "                os.remove(\"word_embeddings.csv\")\n",
        "            if os.path.exists(\"transcription.csv\"):\n",
        "                os.remove(\"transcription.csv\")\n",
        "            if os.path.exists(\"summarization.csv\"):\n",
        "                os.remove(\"summarization.csv\")\n",
        "                \n",
        "            with st.spinner('Running process...'):\n",
        "                # Get the video mp4\n",
        "                mp4_video = stream.download(filename='youtube_video.mp4')\n",
        "                audio_file = open(mp4_video, 'rb')\n",
        "                st.write(youtube_video.title)\n",
        "                st.video(youtube_link) \n",
        "\n",
        "                # Whisper\n",
        "                output = model.transcribe(\"youtube_video.mp4\")\n",
        "                \n",
        "                # Transcription\n",
        "                transcription = {\n",
        "                    \"title\": youtube_video.title.strip(),\n",
        "                    \"transcription\": output['text']\n",
        "                }\n",
        "                data_transcription.append(transcription)\n",
        "                pd.DataFrame(data_transcription).to_csv('transcription.csv') \n",
        "\n",
        "                # Embeddings\n",
        "                segments = output['segments']\n",
        "                for segment in segments:\n",
        "                    openai.api_key = user_secret\n",
        "                    response = openai.Embedding.create(\n",
        "                        input= segment[\"text\"].strip(),\n",
        "                        model=\"text-embedding-ada-002\"\n",
        "                    )\n",
        "                    embeddings = response['data'][0]['embedding']\n",
        "                    meta = {\n",
        "                        \"text\": segment[\"text\"].strip(),\n",
        "                        \"start\": segment['start'],\n",
        "                        \"end\": segment['end'],\n",
        "                        \"embedding\": embeddings\n",
        "                    }\n",
        "                    data.append(meta)\n",
        "                pd.DataFrame(data).to_csv('word_embeddings.csv')\n",
        "                st.success('Completed. Check Tabs for details')\n",
        "\n",
        "                # Summary\n",
        "                summaries, summary_of_summaries = summarization_video(youtube_link)\n",
        "                summarization = {\n",
        "                    \"title\": youtube_video.title.strip(),\n",
        "                    \"summarizations of video in 10mins chunks\": summaries,\n",
        "                    \"overall summary\": summary_of_summaries\n",
        "                }\n",
        "                data_summarization.append(summarization)\n",
        "                pd.DataFrame(data_summarization).to_csv('summarization.csv')\n",
        "\n",
        "st.title(\"Youtube Analyzer ðŸ¤“ \")\n",
        "tab1, tab2, tab3, tab4, tab5 = st.tabs([\"Intro\", \"Transcription\", \"Embedding\", \"Chat with the Video\", \"Summary\"])\n",
        "with tab1:\n",
        "    st.markdown('A simple app that uses openAI\\'s gpt-3 to summarize a youtube video, transcribe it, and ask questions about the video. All without having to watch the video. ')\n",
        "    st.markdown(\"\"\"---\"\"\")\n",
        "    st.write('***What this app does:***')\n",
        "    st.checkbox('Visualize/play the video in the app.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('Transcribe.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('Create embeddings from the video transcript.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('Chat and ask questions about the video.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.markdown(\"\"\"---\"\"\")\n",
        "    st.write('***Progress and features:***')\n",
        "    st.checkbox('Play the youtube video within app.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('If video has transcript already, pull transcript.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('If video doesn\\'t have transcription, use OpenAI\\'s Whisper to transcribe.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('Use Embeddings to segment the text making it suitable for a chatbot application.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('Log embeddings, chat, transcription into a pandas dataframe.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('Q&A / chat with the video.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('Build a quick/simple app using streamlit.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('Alternative option: run streamlit app in colab.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('Multi-language integration: non-English videos compatibility.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.checkbox('Multi-language integration: allow users to ask questions in their languages.', value=True, disabled=True, label_visibility=\"visible\")\n",
        "    st.markdown(\"\"\"---\"\"\")\n",
        "    st.write('***Main tools used:***')\n",
        "    st.write(\"- OpenAI: Whisper, GPT-3.\")\n",
        "    st.write(\"- Streamlit\")\n",
        "    st.markdown(\"\"\"---\"\"\")\n",
        "    st.write('Repo: [Github](https://github.com/ejri/youtube_openai_analysis)')\n",
        "\n",
        "with tab2: \n",
        "    st.header(\"Transcription:\")\n",
        "    if(os.path.exists(\"youtube_video.mp4\")):\n",
        "        audio_file = open('youtube_video.mp4', 'rb')\n",
        "        audio_bytes = audio_file.read()\n",
        "        st.audio(audio_bytes, format='audio/ogg')\n",
        "    if os.path.exists(\"transcription.csv\"):\n",
        "        df = pd.read_csv('transcription.csv')\n",
        "        st.write(df)\n",
        "with tab3:\n",
        "    st.header(\"Embeddings:\")\n",
        "    if os.path.exists(\"word_embeddings.csv\"):\n",
        "        df = pd.read_csv('word_embeddings.csv')\n",
        "        st.write(df)\n",
        "with tab4:\n",
        "    st.header(\"Ask me about the video:\")\n",
        "    if 'generated' not in st.session_state:\n",
        "        st.session_state['generated'] = []\n",
        "\n",
        "    if 'past' not in st.session_state:\n",
        "        st.session_state['past'] = []\n",
        "\n",
        "    def get_text():\n",
        "        input_text = st.text_input(\"You: \",\"\", key=\"input\")\n",
        "        return input_text\n",
        "\n",
        "    user_input = get_text()\n",
        "\n",
        "    def get_embedding_text(api_key, prompt):\n",
        "        openai.api_key = user_secret\n",
        "        response = openai.Embedding.create(\n",
        "            input= prompt.strip(),\n",
        "            model=\"text-embedding-ada-002\"\n",
        "        )\n",
        "        q_embedding = response['data'][0]['embedding']\n",
        "        df=pd.read_csv('word_embeddings.csv', index_col=0)\n",
        "        df['embedding'] = df['embedding'].apply(eval).apply(np.array)\n",
        "\n",
        "        df['distances'] = distances_from_embeddings(q_embedding, df['embedding'].values, distance_metric='cosine')\n",
        "        returns = []\n",
        "        \n",
        "        # Sort by distance with 2 hints\n",
        "        for i, row in df.sort_values('distances', ascending=True).head(4).iterrows():\n",
        "            # Else add it to the text that is being returned\n",
        "            returns.append(row[\"text\"])\n",
        "\n",
        "        # Return the context\n",
        "        return \"\\n\\n###\\n\\n\".join(returns)\n",
        "\n",
        "    def generate_response(api_key, prompt):\n",
        "        one_shot_prompt = '''I am Youtube Analyzer, a highly intelligent question answering bot. If you ask me a question that is rooted in truth, I will give you the answer.\n",
        "        Q: What is human life expectancy in the United States?\n",
        "        A: Human life expectancy in the United States is 78 years.\n",
        "        Q: '''+prompt+'''\n",
        "        A: '''\n",
        "        completions = openai.Completion.create(\n",
        "            engine = \"text-davinci-003\",\n",
        "            prompt = one_shot_prompt,\n",
        "            max_tokens = 1024,\n",
        "            n = 1,\n",
        "            stop=[\"Q:\"],\n",
        "            temperature=0.5,\n",
        "        )\n",
        "        message = completions.choices[0].text\n",
        "        return message\n",
        "\n",
        "    if user_input:\n",
        "        text_embedding = get_embedding_text(user_secret, user_input)\n",
        "        title = pd.read_csv('transcription.csv')['title']\n",
        "        string_title = \"\\n\\n###\\n\\n\".join(title)\n",
        "        user_input_embedding = 'Using this context: \"'+string_title+'. '+text_embedding+'\", answer the following question. \\n'+user_input\n",
        "        # st.write(user_input_embedding)\n",
        "        output = generate_response(user_secret, user_input_embedding)\n",
        "        st.session_state.past.append(user_input)\n",
        "        st.session_state.generated.append(output)\n",
        "    if st.session_state['generated']:\n",
        "        for i in range(len(st.session_state['generated'])-1, -1, -1):\n",
        "            message(st.session_state[\"generated\"][i], key=str(i))\n",
        "            message(st.session_state['past'][i], is_user=True, key=str(i) + '_user')\n",
        "with tab5:    \n",
        "    st.header(\"Video Summary:\")\n",
        "    if os.path.exists(\"summarization.csv\"):\n",
        "        df = pd.read_csv('summarization.csv')\n",
        "        st.write(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsaEcrz5hRzw",
        "outputId": "d69a7dfa-c03f-4d85-b366-ce985651c2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/youtube_openai_analysis/app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "xz80pB-8flss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2Bfcir4KDdaEulSIfp8Wz4EQDEr_4K5t2j653DbxWD57vu74v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkkdBFCef0F9",
        "outputId": "92e7e29e-8dcc-4a8f-8174-5d13ddd8027c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!cp /content/drive/MyDrive/weblm/WebLM_interactive_src/ngrok-stable-linux-amd64.zip /content/youtube_openai_analysis"
      ],
      "metadata": {
        "id": "d-cfyG6sf89e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/youtube_openai_analysis/ngrok-stable-linux-amd64.zip"
      ],
      "metadata": {
        "id": "77ACKvwSgiXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw('./ngrok http 8501 &')"
      ],
      "metadata": {
        "id": "DGAAprP2gos6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTpcvtsUgtSB",
        "outputId": "d5af3a95-4895-4efc-e293-bc71195e77d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://16fd-35-234-174-123.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/youtube_openai_analysis/app.py"
      ],
      "metadata": {
        "id": "beVCHFs0gy0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ajgb-V8Qecfc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}